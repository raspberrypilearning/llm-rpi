## Install Ollama on your Raspberry Pi

--- task ---
Open a Terminal Window on Your Raspberry Pi

To begin, you need to access the terminal. You can do this by clicking on the terminal icon or by pressing `Ctrl + Alt + T`.

![Icon of a terminal window with a grey background and a blue title bar at the top, featuring a white command prompt symbol in the center.](images/terminal.png)

--- /task ---

--- task ---

Install Ollama.

Use the following shell script to install Ollama and the WebUI interface:

```sh
curl -fsSL https://ollama.com/install.sh | sh
```
This installation process might take some time. You will know it's complete when the terminal prompt reappears.

![The installation process of ollama on a linux terminal window. The user types the command and we watch as a progress bar fills and the prompt returns](images/install_ollama.gif)

--- /task ---

### Pull and Run a Model for Your Ollama Instance
In simple terms, "pulling a model" means downloading a specific AI model that Ollama will use to perform tasks. 

There are various models available at [ollama.com/library](https://ollama.com/library){:target="_blank"}. We recommend starting with `gemma:2b`, `phi`, or `tinyllama`. Be cautious with models larger than 5 billion parameters, as they might be too demanding for a standard Raspberry Pi.

--- task ---

Run the following command, replacing `[model name here]` with the name of the model you want to use:

```sh
ollama run [model name here]
```
You will see some progress bars fill up and then be asked to prompt the model.

![Pull and Run Model](images/run_gemma2b.gif)

--- /task ---

--- task ---

Interact with the model by asking it questions, requesting it to write a poem or story, or simply having a chat.

![Prompt the Model](imageURL4)

Press `Ctrl + D` to exit the LLM prompting process when you are done.

--- /task ---

### Using the WebUI
The WebUI works like any other chatbot interface. You can type in your prompts and see the responses generated by the model.

![Open WebUI Interface](imageURL5)

--- task ---

Access the WebUI interface by navigating to `http://localhost:8080/` in your web browser.

![Use Interface](imageURL6)

--- /task ---


--- task ---

Choose which model to use from the dropdown menu at the top of the WebUI. You can also search for and add new models this way.


![Select Models](imageURL7)

--- /task ---